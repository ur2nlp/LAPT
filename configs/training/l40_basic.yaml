max_length: 256

num_train_epochs: 1.0
max_steps: 5000
train_batch_size: 20
gradient_accumulation_steps: 1
learning_rate: 5e-5
lr_scheduler_type: linear
warmup_ratio: 0.0
warmup_steps: 0
max_grad_norm: 1.0

logging_steps: 100
eval_strategy: steps
eval_steps: 500
eval_batch_size: 40
dev_size: 0.0025
save_steps: 500
save_total_limit: 2
early_stopping_patience: null
