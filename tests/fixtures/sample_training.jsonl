{"text": "This is a sample sentence for tokenizer training."}
{"text": "We need enough text to train a small vocabulary."}
{"text": "The quick brown fox jumps over the lazy dog."}
{"text": "Language models process text through tokenization."}
{"text": "SentencePiece can train both BPE and Unigram tokenizers."}
{"text": "Testing requires realistic but minimal data."}
{"text": "These examples should provide sufficient coverage."}
{"text": "Multiple sentences help capture token patterns."}
{"text": "Word frequency matters for vocabulary construction."}
{"text": "Common words appear more often than rare ones."}
